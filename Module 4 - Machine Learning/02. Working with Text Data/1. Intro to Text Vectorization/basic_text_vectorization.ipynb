{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD4dZM5cSfZN"
   },
   "source": [
    "# **Working with Text Data - Text Transformation (AKA Vectorization)**\n",
    "**AKA Feature Extraction | Engineering | Transformation (Text to Numerical Vector)**\n",
    "\n",
    "### **Text Data**\n",
    "\n",
    "Text Analysis is a major application field for machine learning algorithms. Some of the major application areas of NLP are:\n",
    "1. Spell Checker, Keyword Search, etc\n",
    "2. Sentiment Analysis, Spam Classification\n",
    "3. Machine Translation\n",
    "4. Chatbots/Dialog Systems\n",
    "5. Question Answering Systems\n",
    "etc..\n",
    "\n",
    "However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
    "\n",
    "### **Why NLP is hard?**\n",
    "1. Complexity of representation\n",
    "> Poems, Sarcasm, etc...  \n",
    "> Example 1: This task is a piece of cake.  \n",
    "> Example 2: You have a football game tomorrow. Break a leg!\n",
    "\n",
    "2. Ambiguity in Natural Language\n",
    "> Ambiguity means uncertainity of meaning.  \n",
    "> For Example: The car hit the pole while it was moving.\n",
    "\n",
    "### **Vectorization Techniques (AKA Feature Engineering or Extraction - Convert Text to Numerical Vectors)**\n",
    "\n",
    "1. Bag of Words\n",
    "2. TF IDF (Term Frequency - Inverse Document Frequency)\n",
    "3. Word2Vec (by Google)\n",
    "4. GloVe (Global Vectors by Stanford)\n",
    "5. FastText (by Facebook)\n",
    "6. ELMo (Embeddings from Language Models)\n",
    "7. GPT (Generative Pre-trained Transformer by OpenAI)\n",
    "8. BERT (Bidirectional Encoder Representations from Transformer by Google)\n",
    "9. LLM's\n",
    "\n",
    "**Only the following technniques are covered in this notebook:**\n",
    "1. Bag of Words\n",
    "2. TF IDF (Term Frequency - Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F9HiupNmSfZP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "bBaVlqifSfZQ",
    "outputId": "ae540953-0a40-48d8-a446-b43184f686a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text\n",
       "0     it Was the best oF Times $\n",
       "1     It was The worst of times.\n",
       "2     IT 9 was tHe age Of wisdom\n",
       "3  it was thE age of foolishness"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_text = ['it Was the best oF Times $', \n",
    "            'It was The worst of times.',\n",
    "            'IT 9 was tHe age Of wisdom', \n",
    "            'it was thE age of foolishness']\n",
    "\n",
    "df = pd.DataFrame({'text': lst_text})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft7-3UH5SfZe"
   },
   "source": [
    "## **Bag of Word Representation**\n",
    "\n",
    "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the Bag of Words or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document.\n",
    "\n",
    "We will use `CountVectorizer` to **convert text into a matrix of token count**.\n",
    "\n",
    "`Bag of Words`: https://machinelearningmastery.com/gentle-introduction-bag-words-model/\n",
    "\n",
    "`Code Example`: https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/  \n",
    "\n",
    "**We are going to perform below mentioned steps to understand the entire process:**  \n",
    "a. Converting text to numerical vectors with the help of `CountVectorizer`  \n",
    "b. Understand `fit` and `transform`  \n",
    "c. Looking at `vocabulary_`  \n",
    "d. Converting sparse matrix to dense matrix using `toarray()`  \n",
    "e. Understanding `n_gram`  \n",
    "\n",
    "### **Advantages**\n",
    "1. It is simple to understand and implement like OneHotEncoding.\n",
    "2. We have a fixed length encoding for any sequence of arbitrary length.\n",
    "3. Documents with same words/vocabulary will have similar representation. So if two documents have a similar vocabulary, they’ll be closer to each other in the vector space and vice versa.\n",
    "\n",
    "### **Disadvantages**\n",
    "1. The size of vector increases with the size of the vocabulary. Thus, sparsity continues to be a problem. One way to control it is by limiting the vocabulary to n number of the most frequent words.\n",
    "2. It does not capture the similarity between different words that mean the same thing. i.e. Semantic Meaning is not captured.\n",
    "> a. \"walk\", \"walked\", and \"walking\". BoW vectors of all three tokens will be equally apart.  \n",
    "> b. \"search\" and \"explore\" are synonyms. BoW won't capture the semantic similarity of these words.\n",
    "3. This representation does not have any way to handle out of vocabulary (OOV) words (i.e., new words that were not seen in the corpus that was used to build the vectorizer).\n",
    "4. As the name indicates, it is a “bag” of words. Word order information is lost in this representation. One way to control it is by using n-grams.\n",
    "5. It suffers from **curse of high dimensionality.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "kvvDKA6wSfZf",
    "outputId": "8a7f1dbc-11cc-4e1a-faad-9d689f629cf2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it Was the best oF Times $</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was The worst of times.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IT 9 was tHe age Of wisdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it was thE age of foolishness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            text\n",
       "0     it Was the best oF Times $\n",
       "1     It was The worst of times.\n",
       "2     IT 9 was tHe age Of wisdom\n",
       "3  it was thE age of foolishness"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **a. BoW Text Vectorization: Apply CountVectorizer**\n",
    "\n",
    "**Parameters**\n",
    "1. encoding: str, default='utf-8'\n",
    "2. decode_error: {'strict', 'ignore', 'replace'}, default='strict' \n",
    "    - Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given `encoding`.\n",
    "3. token_pattern: str or None, default=r\"(?u)\\b\\w\\w+\\b\"\n",
    "    - Regular expression denoting what constitutes a \"token\". The default regexp select tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator).\n",
    "    - If there is a capturing group in token_pattern then the captured group content, not the entire match, becomes the token. At most one capturing group is permitted.\n",
    "4. ngram_range: tuple (min_n, max_n), default=(1, 1)\n",
    "    - The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used. For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams.\n",
    "5. strip_accents: {'ascii', 'unicode'}, default=None\n",
    "    - Remove accents and perform other character normalization during the preprocessing step.\n",
    "6. lowercase: bool, default=True\n",
    "    - Convert all characters to lowercase before tokenizing.\n",
    "7. preprocessor: callable, default=None\n",
    "    - Override the preprocessing (strip_accents and lowercase) stage while preserving the tokenizing and n-grams generation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sm6L-q4cSfZg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DTM (# of docs, # of unique vocabulary): (4, 10)\n",
      "Type of DTM (i.e. Compressed Sparse Row (CSR) format): <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Bag of Words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.\n",
    "bow_vect = CountVectorizer()\n",
    "\n",
    "# fit_transform() does two functions: \n",
    "# First, it fits and learns the vocabulary \n",
    "# Second, it transforms our training data into feature vectors\n",
    "# The input to fit_transform should be a list of strings\n",
    "dtm = bow_vect.fit_transform(df['text'])\n",
    "\n",
    "print(f\"Shape of DTM (# of docs, # of unique vocabulary): {dtm.shape}\")\n",
    "\n",
    "print(f\"Type of DTM (i.e. Compressed Sparse Row (CSR) format): {type(dtm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNjyY1QySfZk"
   },
   "source": [
    "**Remember:**\n",
    "\n",
    "- `bow_vect.fit(lst_text)` **learns the vocabulary**\n",
    "- `bow_vect.transform(lst_text)` **uses the fitted vocabulary** to build a **document-term matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpfrc21bSfZg",
    "outputId": "28abe17e-4992-4eb5-d88d-365baadca6a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10\n",
      "\n",
      "Let's look at the vocabulary stored in the object: \n",
      "{'it': 3, 'was': 7, 'the': 5, 'best': 1, 'of': 4, 'times': 6, 'worst': 9, 'age': 0, 'wisdom': 8, 'foolishness': 2}\n",
      "\n",
      "Output Feature Names: ['age' 'best' 'foolishness' 'it' 'of' 'the' 'times' 'was' 'wisdom' 'worst']\n"
     ]
    }
   ],
   "source": [
    "# We can look at unique words by using 'vocabulary_'\n",
    "\n",
    "print(f\"Vocabulary size: {len(bow_vect.vocabulary_)}\")\n",
    "print()\n",
    "print(f\"Let's look at the vocabulary stored in the object: \\n{bow_vect.vocabulary_}\")\n",
    "print()\n",
    "print(\"Output Feature Names:\", bow_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 1 1 1 0 0]\n",
      " [0 0 0 1 1 1 1 1 0 1]\n",
      " [1 0 0 1 1 1 0 1 1 0]\n",
      " [1 0 1 1 1 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Since the dtm is sparse, lets convert it into numpy array.\n",
    "\n",
    "print(dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4RsgNj2SfZh",
    "outputId": "383378b0-7067-4fef-b27b-f1c2b514c19a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 6)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 9)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 7)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 8)\t1\n",
      "  (3, 3)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 0)\t1\n",
      "  (3, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "# Lets look at the Compressed Sparse Row (CSR) format\n",
    "\n",
    "print(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "jHFHo3o8SfZi",
    "outputId": "225e0bbf-875f-405f-a5a4-640f7634363f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>it</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>was</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  best  foolishness  it  of  the  times  was  wisdom  worst\n",
       "0    0     1            0   1   1    1      1    1       0      0\n",
       "1    0     0            0   1   1    1      1    1       0      1\n",
       "2    1     0            0   1   1    1      0    1       1      0\n",
       "3    1     0            1   1   1    1      0    1       0      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the sparse matrix to a dataframe\n",
    "\n",
    "pd.DataFrame(dtm.toarray(), \n",
    "             columns=bow_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **b. BoW Text Vectorization: Apply CountVectorizer with `ngram_range=(1,2)` and `lowercase=False`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x6z37rArSfZj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DTM (# of docs, # of unique vocabulary): (4, 39)\n",
      "Type of DTM (i.e. Compressed Sparse Row (CSR) format): <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vect = CountVectorizer(ngram_range=(1,2), lowercase=False)\n",
    "\n",
    "dtm = bow_vect.fit_transform(df['text'])\n",
    "\n",
    "print(f\"Shape of DTM (# of docs, # of unique vocabulary): {dtm.shape}\")\n",
    "\n",
    "print(f\"Type of DTM (i.e. Compressed Sparse Row (CSR) format): {type(dtm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x39 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 44 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShdbxBF-SfZj",
    "outputId": "e2090759-db69-43e2-c614-167650facb58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 39\n",
      "\n",
      "Let's look at the vocabulary stored in the object: \n",
      "{'it': 17, 'Was': 9, 'the': 29, 'best': 14, 'oF': 20, 'Times': 8, 'it Was': 18, 'Was the': 10, 'the best': 30, 'best oF': 15, 'oF Times': 21, 'It': 2, 'was': 32, 'The': 6, 'worst': 37, 'of': 22, 'times': 31, 'It was': 3, 'was The': 33, 'The worst': 7, 'worst of': 38, 'of times': 24, 'IT': 0, 'tHe': 25, 'age': 11, 'Of': 4, 'wisdom': 36, 'IT was': 1, 'was tHe': 34, 'tHe age': 26, 'age Of': 12, 'Of wisdom': 5, 'thE': 27, 'foolishness': 16, 'it was': 19, 'was thE': 35, 'thE age': 28, 'age of': 13, 'of foolishness': 23}\n",
      "\n",
      "Output Feature Names: ['IT' 'IT was' 'It' 'It was' 'Of' 'Of wisdom' 'The' 'The worst' 'Times'\n",
      " 'Was' 'Was the' 'age' 'age Of' 'age of' 'best' 'best oF' 'foolishness'\n",
      " 'it' 'it Was' 'it was' 'oF' 'oF Times' 'of' 'of foolishness' 'of times'\n",
      " 'tHe' 'tHe age' 'thE' 'thE age' 'the' 'the best' 'times' 'was' 'was The'\n",
      " 'was tHe' 'was thE' 'wisdom' 'worst' 'worst of']\n"
     ]
    }
   ],
   "source": [
    "# We can look at unique words by using 'vocabulary_'\n",
    "\n",
    "print(f\"Vocabulary size: {len(bow_vect.vocabulary_)}\")\n",
    "print()\n",
    "print(f\"Let's look at the vocabulary stored in the object: \\n{bow_vect.vocabulary_}\")\n",
    "print()\n",
    "print(\"Output Feature Names:\", bow_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUB8kQ39SfZj",
    "outputId": "4893a434-ebcd-4a40-bd06-eb0ead284f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0]\n",
      " [0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0\n",
      "  0 1 1]\n",
      " [1 1 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0\n",
      "  1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 1 0 0 1\n",
      "  0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# convert sparse matrix to numpy array\n",
    "print(dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "TFIswN7TSfZk",
    "outputId": "323138bf-7e5c-42a1-8f2e-b29bdce2e221"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IT</th>\n",
       "      <th>IT was</th>\n",
       "      <th>It</th>\n",
       "      <th>It was</th>\n",
       "      <th>Of</th>\n",
       "      <th>Of wisdom</th>\n",
       "      <th>The</th>\n",
       "      <th>The worst</th>\n",
       "      <th>Times</th>\n",
       "      <th>Was</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>the best</th>\n",
       "      <th>times</th>\n",
       "      <th>was</th>\n",
       "      <th>was The</th>\n",
       "      <th>was tHe</th>\n",
       "      <th>was thE</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "      <th>worst of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IT  IT was  It  It was  Of  Of wisdom  The  The worst  Times  Was  ...  \\\n",
       "0   0       0   0       0   0          0    0          0      1    1  ...   \n",
       "1   0       0   1       1   0          0    1          1      0    0  ...   \n",
       "2   1       1   0       0   1          1    0          0      0    0  ...   \n",
       "3   0       0   0       0   0          0    0          0      0    0  ...   \n",
       "\n",
       "   the  the best  times  was  was The  was tHe  was thE  wisdom  worst  \\\n",
       "0    1         1      0    0        0        0        0       0      0   \n",
       "1    0         0      1    1        1        0        0       0      1   \n",
       "2    0         0      0    1        0        1        0       1      0   \n",
       "3    0         0      0    1        0        0        1       0      0   \n",
       "\n",
       "   worst of  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         0  \n",
       "\n",
       "[4 rows x 39 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the sparse matrix to a dataframe\n",
    "\n",
    "pd.DataFrame(dtm.toarray(), \n",
    "             columns=bow_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mYc-Zk2SfZl"
   },
   "source": [
    "## **Term Frequency - Inverse Document Frequency (TF IDF)**\n",
    "\n",
    "In BOW approach all the words in the text are treated as equally important i.e. there's no notion of some words in the document being more important than others. TF-IDF, or term frequency-inverse document frequency, addresses this issue. It aims to quantify the importance of a given word relative to other words in the document and in the corpus.\n",
    "\n",
    "***\n",
    "\n",
    "Let's now try to understand:\n",
    "1. Term Frequency  \n",
    "2. Inverse Document Frequency\n",
    "\n",
    "$$ TF \\ IDF = TF(word_i, doc_j) * IDF(word_i, corpus) $$\n",
    "\n",
    "$$ TF(word_i, doc_j) = \\frac{No \\ of \\ time \\ word_i \\ occurs \\ in \\ doc_j}{Total \\ no \\ of \\ words \\ in \\ doc_j} $$\n",
    "\n",
    "$$ IDF(word_i, corpus) = \\log_n(\\frac{No \\ of \\ docs \\ in \\ corpus}{No \\ of \\ docs \\ which \\ contains \\ word_i}) $$\n",
    "\n",
    "***\n",
    "\n",
    "### **Advantages**\n",
    "1. If the word is rare in the corpus, it will be given more importance. (i.e. IDF)\n",
    "2. If the word is more frequent in a document, it will be given more importance. (i.e. TF)\n",
    "\n",
    "### **Disadvantages**\n",
    "> **Same as BOW**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TF IDF Text Vectorization: Apply TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "TVjKE9x_SfZl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output (# of docs, # of unique vocabulary): (4, 10)\n",
      "Type of output (i.e. Compressed Sparse Row (CSR) format): <class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "out = tfidf_vect.fit_transform(df['text'])\n",
    "\n",
    "print(f\"Shape of output (# of docs, # of unique vocabulary): {out.shape}\")\n",
    "\n",
    "print(f\"Type of output (i.e. Compressed Sparse Row (CSR) format): {type(out)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYKtDLK0SfZm",
    "outputId": "d192c9ff-8316-4224-fe87-75b8d8b7e878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10\n",
      "\n",
      "Let's look at the vocabulary stored in the object: \n",
      "{'it': 3, 'was': 7, 'the': 5, 'best': 1, 'of': 4, 'times': 6, 'worst': 9, 'age': 0, 'wisdom': 8, 'foolishness': 2}\n",
      "\n",
      "Output Feature Names: ['age' 'best' 'foolishness' 'it' 'of' 'the' 'times' 'was' 'wisdom' 'worst']\n"
     ]
    }
   ],
   "source": [
    "# We can look at unique words by using 'vocabulary_'\n",
    "\n",
    "print(f\"Vocabulary size: {len(tfidf_vect.vocabulary_)}\")\n",
    "print()\n",
    "print(f\"Let's look at the vocabulary stored in the object: \\n{tfidf_vect.vocabulary_}\")\n",
    "print()\n",
    "print(\"Output Feature Names:\", tfidf_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqecWwkpSfZm",
    "outputId": "d789011c-d7b9-4a72-b92a-c60ab9afca42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.60735961 0.         0.31694544 0.31694544 0.31694544\n",
      "  0.4788493  0.31694544 0.         0.        ]\n",
      " [0.         0.         0.         0.31694544 0.31694544 0.31694544\n",
      "  0.4788493  0.31694544 0.         0.60735961]\n",
      " [0.4788493  0.         0.         0.31694544 0.31694544 0.31694544\n",
      "  0.         0.31694544 0.60735961 0.        ]\n",
      " [0.4788493  0.         0.60735961 0.31694544 0.31694544 0.31694544\n",
      "  0.         0.31694544 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# convert sparse matrix to nparray\n",
    "\n",
    "print(out.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "TSQ5mn5dSfZm",
    "outputId": "6a0d5b3b-9acd-4d0b-ce7d-621a5df21bbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>it</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>was</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60736</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.478849</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.478849</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.60736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478849</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.60736</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.478849</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.60736</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316945</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     best  foolishness        it        of       the     times  \\\n",
       "0  0.000000  0.60736      0.00000  0.316945  0.316945  0.316945  0.478849   \n",
       "1  0.000000  0.00000      0.00000  0.316945  0.316945  0.316945  0.478849   \n",
       "2  0.478849  0.00000      0.00000  0.316945  0.316945  0.316945  0.000000   \n",
       "3  0.478849  0.00000      0.60736  0.316945  0.316945  0.316945  0.000000   \n",
       "\n",
       "        was   wisdom    worst  \n",
       "0  0.316945  0.00000  0.00000  \n",
       "1  0.316945  0.00000  0.60736  \n",
       "2  0.316945  0.60736  0.00000  \n",
       "3  0.316945  0.00000  0.00000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the sparse matrix to a dataframe\n",
    "\n",
    "pd.DataFrame(out.toarray(), \n",
    "             columns=tfidf_vect.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
