{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6184a554-1851-4a31-abf1-87c2561f29be",
   "metadata": {},
   "source": [
    "## **Chains (Legacy)**\n",
    "\n",
    "Chains allows us to link the output of one LLM call as the input of another call.\n",
    "\n",
    "Below we report on the legacy chain types that exist. We will maintain support for these until we are able to create a LCEL alternative. We will cover:\n",
    "1. LLMChain\n",
    "2. SequentialChain\n",
    "3. LLMRouterChain\n",
    "4. TransformerChain\n",
    "5. etc...\n",
    "\n",
    "Note that, Chains have a basic building block known as an LLMChain object. You can think of the LLMChain as just a simple LLM call that will have an input and an output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9062e-1cac-4264-b40c-b26f406810f2",
   "metadata": {},
   "source": [
    "## **LLMChain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa15d575-4524-41b8-a4a1-f3da57950631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Key\n",
    "\n",
    "f = open('keys/.openai_api_key.txt')\n",
    "\n",
    "OPENAI_API_KEY = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c3e157e-dd82-4541-925e-70a640a3723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069c2668-961a-43ba-a5ee-ff85b0297cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot who expertise in Data Science Tutor. You are known to make any complex topic simpler even for a beginner.\"),\n",
    "        (\"human\", \"What is {topic}?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af9b77b3-15b6-4969-81db-ca93e76d7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=chat_model, prompt=chat_template)\n",
    "\n",
    "input = {\"topic\": \"Feature Selection\"}\n",
    "\n",
    "result = chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5440562-fc15-4a3f-a321-f66a80a23537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Feature Selection',\n",
       " 'text': \"Feature selection is the process of selecting a subset of relevant features (variables, predictors) from a larger set of features to use in building a machine learning model. The goal of feature selection is to improve the model's performance by reducing overfitting, increasing interpretability, and reducing the computational cost.\\n\\nThere are different techniques for feature selection, such as filter methods, wrapper methods, and embedded methods. Filter methods evaluate the relevance of features based on their statistical properties, wrapper methods use a specific machine learning algorithm to evaluate the importance of features, and embedded methods incorporate feature selection as part of the model training process.\\n\\nOverall, feature selection helps in improving the model's accuracy, reducing the complexity of the model, and enhancing the interpretability of the results.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5684de3e-ab75-4792-b353-c2fcd18bb890",
   "metadata": {},
   "source": [
    "## **SimpleSequentialChain**\n",
    "\n",
    "Now that we understood how to use LLMChain object, we can chain them together to create more complex functionality with LangChain.\n",
    "\n",
    "Let's now understand this with the following example:\n",
    "1. Take an input topic from the user\n",
    "2. Using the user input generate an outline for a blog\n",
    "3. Using the blog outline generate the technical blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d094ae5-50da-49a4-b3e9-389244181bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61418f6f-9ae7-4368-b997-c222774f85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI Key and initialize a ChatModel\n",
    "chat_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc73e90d-daec-4432-bb12-85b2245dede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the user input generate an outline for a blog\n",
    "\n",
    "chat_template_one = ChatPromptTemplate.from_template(\n",
    "    \"Given me a simple bullet point outline for a blog post on {topic}.\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(llm=chat_model, prompt=chat_template_one, output_key=\"outline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "585b9363-35ea-4edd-80d3-104062388f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the blog outline generate the technical blog post\n",
    "\n",
    "chat_template_two = ChatPromptTemplate.from_template(\n",
    "    \"Write a technical blog post using this outline {outline}.\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(llm=chat_model, prompt=chat_template_two, output_key=\"blog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9960971a-a8b7-4326-88e1-768786fab49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "full_chain = SequentialChain(chains=[chain_one, chain_two], \n",
    "                             input_variables=['topic'], \n",
    "                             output_variables=['outline', 'blog'], \n",
    "                             verbose=True)\n",
    "\n",
    "input = {\"topic\": \"One hot encoding\"}\n",
    "\n",
    "result = full_chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e67b76e7-e7b2-4029-87a5-1c6189e449ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'One hot encoding',\n",
       " 'outline': '- Introduction to one hot encoding\\n- Explanation of what one hot encoding is and why it is used in machine learning\\n- Steps involved in one hot encoding\\n- Example of one hot encoding in action\\n- Advantages and disadvantages of one hot encoding\\n- Conclusion and final thoughts on the importance of one hot encoding in data preprocessing.',\n",
       " 'blog': 'Introduction to One Hot Encoding\\n\\nIn the world of machine learning and data preprocessing, one hot encoding is a commonly used technique to convert categorical data into numerical data. This process is important because machine learning algorithms typically work with numerical data, and converting categorical data into numerical form allows these algorithms to better understand and process the data.\\n\\nExplanation of One Hot Encoding and its Importance in Machine Learning\\n\\nOne hot encoding is a technique where categorical variables are converted into a binary matrix representation. Each category is represented as a binary vector where only one element is hot (1) and all others are cold (0). This allows machine learning algorithms to properly understand and process categorical data.\\n\\nOne hot encoding is important in machine learning because it helps improve the performance and accuracy of the algorithms. By converting categorical variables into numerical form, the algorithms can better understand the relationships between different categories and make more accurate predictions.\\n\\nSteps Involved in One Hot Encoding\\n\\nThe steps involved in one hot encoding are as follows:\\n1. Identify the categorical variables that need to be encoded.\\n2. Create a binary matrix where each category is represented as a binary vector.\\n3. Replace the categorical variables with the binary matrix in the dataset.\\n\\nExample of One Hot Encoding in Action\\n\\nLet\\'s say we have a dataset with a categorical variable \"color\" with three categories: red, green, and blue. One hot encoding this variable would result in a binary matrix where each category is represented as follows:\\n- Red: [1, 0, 0]\\n- Green: [0, 1, 0]\\n- Blue: [0, 0, 1]\\n\\nAdvantages and Disadvantages of One Hot Encoding\\n\\nAdvantages:\\n- Preserves the information in the categorical variables.\\n- Improves the performance of machine learning algorithms.\\n- Easy to implement and understand.\\n\\nDisadvantages:\\n- Increases the dimensionality of the dataset.\\n- Can lead to the \"curse of dimensionality\" in some cases.\\n\\nConclusion and Final Thoughts on the Importance of One Hot Encoding in Data Preprocessing\\n\\nIn conclusion, one hot encoding is a crucial technique in data preprocessing for machine learning. By converting categorical variables into numerical form, it helps improve the performance and accuracy of machine learning algorithms. While it has some drawbacks, the advantages of one hot encoding far outweigh the disadvantages, making it an essential step in the data preprocessing pipeline.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "525e453e-c8c3-49a2-a314-b73d1c0c60c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Introduction to one hot encoding\n",
      "- Explanation of what one hot encoding is and why it is used in machine learning\n",
      "- Steps involved in one hot encoding\n",
      "- Example of one hot encoding in action\n",
      "- Advantages and disadvantages of one hot encoding\n",
      "- Conclusion and final thoughts on the importance of one hot encoding in data preprocessing.\n"
     ]
    }
   ],
   "source": [
    "print(result['outline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b6f1318-3a5c-4007-95f1-c241fe1006eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to One Hot Encoding\n",
      "\n",
      "In the world of machine learning and data preprocessing, one hot encoding is a commonly used technique to convert categorical data into numerical data. This process is important because machine learning algorithms typically work with numerical data, and converting categorical data into numerical form allows these algorithms to better understand and process the data.\n",
      "\n",
      "Explanation of One Hot Encoding and its Importance in Machine Learning\n",
      "\n",
      "One hot encoding is a technique where categorical variables are converted into a binary matrix representation. Each category is represented as a binary vector where only one element is hot (1) and all others are cold (0). This allows machine learning algorithms to properly understand and process categorical data.\n",
      "\n",
      "One hot encoding is important in machine learning because it helps improve the performance and accuracy of the algorithms. By converting categorical variables into numerical form, the algorithms can better understand the relationships between different categories and make more accurate predictions.\n",
      "\n",
      "Steps Involved in One Hot Encoding\n",
      "\n",
      "The steps involved in one hot encoding are as follows:\n",
      "1. Identify the categorical variables that need to be encoded.\n",
      "2. Create a binary matrix where each category is represented as a binary vector.\n",
      "3. Replace the categorical variables with the binary matrix in the dataset.\n",
      "\n",
      "Example of One Hot Encoding in Action\n",
      "\n",
      "Let's say we have a dataset with a categorical variable \"color\" with three categories: red, green, and blue. One hot encoding this variable would result in a binary matrix where each category is represented as follows:\n",
      "- Red: [1, 0, 0]\n",
      "- Green: [0, 1, 0]\n",
      "- Blue: [0, 0, 1]\n",
      "\n",
      "Advantages and Disadvantages of One Hot Encoding\n",
      "\n",
      "Advantages:\n",
      "- Preserves the information in the categorical variables.\n",
      "- Improves the performance of machine learning algorithms.\n",
      "- Easy to implement and understand.\n",
      "\n",
      "Disadvantages:\n",
      "- Increases the dimensionality of the dataset.\n",
      "- Can lead to the \"curse of dimensionality\" in some cases.\n",
      "\n",
      "Conclusion and Final Thoughts on the Importance of One Hot Encoding in Data Preprocessing\n",
      "\n",
      "In conclusion, one hot encoding is a crucial technique in data preprocessing for machine learning. By converting categorical variables into numerical form, it helps improve the performance and accuracy of machine learning algorithms. While it has some drawbacks, the advantages of one hot encoding far outweigh the disadvantages, making it an essential step in the data preprocessing pipeline.\n"
     ]
    }
   ],
   "source": [
    "print(result['blog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8294017-f75c-4985-ba76-5f4f2567991c",
   "metadata": {},
   "source": [
    "## **LLMRouterChains (Coming Soon)**\n",
    "\n",
    "LLMRouterChains can take in an input and redirect it to the most appropriate LLMChain sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "272063d0-b80b-422d-8842-fb27b7d2917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coming Soon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
